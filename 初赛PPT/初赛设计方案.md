# OpenRisk-Advisor：开源项目衰退风险预测与治理建议系统

## 第 1 页｜封面（主题）

本作品面向开源治理与运营的真实场景，围绕“项目是否正在衰退、是否需要介入、应如何介入”三类核心决策问题，提出一套可部署、可复现的工程化系统。系统以 OpenDigger 的开源生态数据为输入，以 IoTDB 管理多指标时间序列，并在此基础上实现衰退风险预测、风险信号归因解释以及大模型辅助治理建议生成，最终以可视化与告警方式呈现给维护者与 OSPO 用户，形成从“发现问题”到“建议行动”的闭环。

---

## 第 2 页｜背景与问题定义（主题）  

开源项目在现实中并不总是“突然停止”，更常见的情况是进入一个缓慢但持续的衰退过程：贡献者减少、提交频率下降、Issue/PR 处理滞后、核心成员流失、讨论热度降低等。这类变化往往在早期并不显著，靠维护者经验或简单的趋势图很难及时识别；一旦外部用户感知到“项目变慢”，通常已经错过最佳介入窗口。对企业 OSPO 或基金会来说，项目衰退意味着依赖风险、技术路线风险与投入回报下降；对维护者来说，衰退意味着维护负担增加、贡献者更难吸引、社区生态进一步恶化。因此，一个面向治理的系统不仅需要“描述现状”，更需要“提前预警并给出可行动的介入建议”。

但“衰退”在数据层面并不是一个天然标签，最大的难点在于：必须把“异常的持续性下滑”与“正常的周期性波动/结构性变化”区分开。现实中最容易被误判的情况包括：节假日与季节性造成的短期低谷、版本发布节奏带来的周期峰谷、以及项目进入成熟期后“更少提交但更稳定”的自然减速。如果系统只盯着某个指标的绝对值下降或短期斜率，很容易把“假期低谷”或“成熟稳定”误判为衰退，进而削弱系统的可信度与治理价值。

现有生态分析作品多停留在“历史数据展示”“指标汇总与排名”“静态健康度评分”，它们能够回答“过去发生了什么”，但难以回答治理更关心的问题：接下来是否存在风险、风险来自哪里、应该采取什么动作。因此，本项目的问题定义是：在开源治理与运营场景下，构建一套可复用的“衰退风险预警—解释证据—行动建议”能力，将生态数据真正转化为运营决策与资源配置的依据。

我们将“衰退风险”定义为一个概率化概念：在未来一个观察窗口内（例如未来 1～3 个月），项目在活跃度、贡献者规模、协作效率等关键维度出现“异常且持续”的负向变化的概率。这里的关键词是“异常”与“持续”——我们关注的不是“提交少了”，而是“在排除季节性与成熟期影响后，是否出现了需要治理介入的持续性下滑信号”。为此，系统在特征层显式引入同比/环比等相对变化视角，并配合时序窗口化统计来抑制短期噪声，从机制上降低节假日低谷与生命周期自然减速导致的误报风险；而风险输出将以“风险概率 + 证据摘要”的形式呈现，为后续的解释与建议生成提供可靠支撑。

系统默认采用“相对变化优先、窗口化抑噪、持续性判定”的风险识别原则：以同比/环比视角刻画相对变化趋势，用滑动窗口聚合降低短期波动干扰，并要求风险信号具备跨窗口持续性。所有阈值与窗口参数均配置化，便于在不同项目与不同时间粒度下复用与迭代验证。

---

## 第 3 页｜目标用户与需求分析（应用场景）

本系统的目标用户分为三类。第一类是开源项目维护者（Maintainer），其核心需求是快速判断“项目是否在走下坡路”，并获取可执行的治理建议（例如引入贡献者、优化 triage、发布路线图、改进响应流程）。第二类是企业 OSPO 或技术管理者，其核心需求是以较低成本监控多个依赖项目的风险，及时发现需要介入或替代的项目，并为内部资源投入提供依据。第三类是开源社区运营人员或基金会项目负责人，其核心需求是面向项目集群的风险排查、重点扶持对象发现以及运营活动效果评估。

围绕上述用户，我们将系统需求拆成三层。第一层是“监控与预警”：支持批量项目接入、风险看板、风险排行榜、阈值告警与时间轴回放，强调高可用与可解释。第二层是“预测与解释”：系统不仅给出风险分数，还要明确风险来源于哪些指标维度、在哪个时间段开始出现异常，以及异常是否具有持续性。第三层是“行动建议”：针对识别出的风险信号，系统输出治理动作建议，并说明建议与信号之间的因果对应关系，避免泛泛而谈。

需求的工程化表达是：系统必须具备可扩展的数据管道（以适配多个项目与更多指标），具备可复现的风险评分方法（可离线训练/更新），具备稳定的在线查询与可视化能力，并且建议模块要有“证据输入”，从而保证输出内容具备可信度和可追溯性。

---

## 第 4 页｜总体方案与技术选型（设计方案 + 技术挑战）

系统采用“数据采集—时序存储—风险建模—解释归因—LLM 建议—可视化交互”的分层架构，面向开源治理与运营形成一条可复现、可审计、可持续迭代的技术链路。总体思路是把开源生态指标视为多维时序信号：先用统一的数据与特征流水线将其规范化为可计算的指标字典，再通过风险模型输出概率化的风险分数与结构化证据，最后把证据交给大模型进行“基于数据的建议生成”，从根源上避免大模型在治理场景中出现凭空臆测式输出。系统输出以 RiskReport 为核心对象（风险分数/等级 + 触发信号列表 + 支撑证据摘要），并贯穿看板展示、自然语言查询与建议生成三类用户体验。

在技术选型上，我们严格对齐赛项推荐工具集并强调各组件在架构中的职责边界：OpenDigger 负责提供开源项目与社区的多维指标数据，并作为数据源侧的可追溯依据；IoTDB 作为统一的时序存储与计算底座，承载原始与衍生指标，并通过滑动窗口聚合、同比/环比与异常度计算为风险建模提供高质量输入；风险建模层以“弱监督可落地 + 可升级”为原则，先以信号与轻量模型交付稳定预测，再可平滑升级到轻量时序深度模型以提升捕捉复杂模式的能力；解释归因层将模型输出映射为可读的触发信号与指标对比证据，直接服务于评审问答与治理决策。面向应用层，DataEase 用于构建运营视角的交互式看板与项目风险地图；SQLBot 提供自然语言到 SQL 的查询入口，降低非技术人员检索与排查成本；MaxKB 用于沉淀治理知识库与最佳实践，作为建议生成阶段的检索增强来源，确保输出建议可对齐“证据—原因—行动”链路。大模型侧采用可替换的 LLM 接口并与业务逻辑解耦，便于在本地/云端模型之间切换，同时支持安全策略与输出格式约束，保证部署可行性与可控性。

该方案的工程优势体现在“稳定接口 + 分层替换”：数据层与指标字典一旦固化，建模层可以从规则/统计模型逐步升级而不破坏系统；建议层可以替换不同 LLM 或不同知识库而不影响风险评分的可复现性；可视化与查询层可并行迭代，持续提升可用性与展示效果。通过这种分层架构，我们把“生态数据洞察”升级为“可预测、可解释、可行动”的治理决策支持系统，满足初赛对主题契合、技术挑战与设计方案清晰度的高要求。

***PPT制作***：可以画一个清晰的“数据流管道图”，左边脏数据进，右边治理建议出。

---

## 第 5 页｜数据来源、指标体系与衰退信号定义（技术挑战）

### 数据来源：OpenDigger 的官方数据使用方式（Static Data Root）

本项目的数据层以 OpenDigger 生产的“静态指标数据”为来源，严格按其官方文档给出的静态数据根链接获取指标文件：  
- 静态数据根链接统一为：`https://oss.open-digger.cn/{platform}/{org/login}/{repo}/`  
  - `platform` 官方支持 `github` 与 `gitee`  
  - 对于仓库类对象：使用 `{org}/{repo}`；对于开发者类对象：使用 `{login}`（按 OpenDigger 文档约定）  
- 指标文件为 JSON 对象，时间键在同一层级中按官方口径给出：  
  - 月度：`YYYY-MM`  
  - 季度：`YYYYQX`  
  - 年度：`YYYY`  
- 数据缺失处理遵循 OpenDigger 的约定：当存在 `YYYY-MM-raw` 时，表示该月的原始值；对应的 `YYYY-MM` 为插值后的连续值。工程上我们将同时保留 `raw` 与“连续值”两条序列：  
  - “连续值”用于建模与展示（保持时序连续性）  
  - `-raw` 用于审计与回溯（解释数据缺口带来的不确定性）

### 时间粒度策略：以“月度”为主，季度/年度作为稳定参照

由于 OpenDigger 指标天然提供月/季/年三个粒度，我们在风险早预警场景中默认采用“月度主序列”，并辅以：  
- 季度（`YYYYQX`）：用于降低短期波动影响，作为“是否持续性恶化”的稳健参照；  
- 年度（`YYYY`）：用于生命周期阶段判断（成熟期长期稳定 vs 长期下行）。  
后续若需要更细粒度的“周”视角，我们不在数据源层强行伪造周数据，而是在存储与查询层（IoTDB）通过窗口化聚合与稳健估计形成“近似周级信号”，并明确标注其为“窗口统计结果”而非 OpenDigger 原生粒度（避免口径混乱）。

### 指标体系：以治理与运营为导向的 Metric Dictionary（不做“影响力排名中心化”）

我们不把重点放在单一热度或排名，而是围绕“可持续协作”构建指标字典。所有“原始指标”均保持 OpenDigger 的文件与命名口径；所有“衍生特征”均标注为本项目计算结果（写入 IoTDB 的派生序列），避免与 OpenDigger 指标混淆。

指标分为四类（每类均包含 Level / Change / Stability 三层特征），并额外引入 OpenDigger 的 OpenRank 作为跨维度的综合参照信号：

1. **活跃度（Activity / Throughput）**  
   目标是刻画项目产出节奏与开发流水线是否“持续运转”。数据来源选择 OpenDigger 已产出的仓库统计指标（以其指标文件为准），典型体现为代码变更与协作事件的活跃水平。  
   - Level：月度值 + 季度/年度对照  
   - Change：月环比变化、同比变化（以同月/同季度对齐对比）  
   - Stability：跨季度的趋势一致性（是否只是单月下滑）

2. **贡献者结构（Contributors / Concentration）**  
   目标是刻画“是否有人做事、是否形成可持续团队”，关注核心贡献者与贡献集中度的结构风险。数据来源为 OpenDigger 的开发者/仓库维度统计指标（以其文件为准）。  
   - Level：活跃贡献者规模、核心贡献者规模（若对应指标可用）  
   - Change：核心群体是否持续缩小  
   - Stability：贡献是否向少数人异常集中（单点风险）

3. **协作效率（Collaboration Efficiency）**  
   目标是刻画“问题是否能被处理掉”，对应维护负担与治理摩擦。优先使用 OpenDigger 的流程效率类指标（例如 Issue Age 等在 OpenDigger 指标体系中明确给出的效率指标），并与事件量类指标联合解释。  
   - Level：效率指标本身（如 age/响应相关指标的月度值）  
   - Change：效率指标是否连续恶化（不仅是单月抖动）  
   - Stability：季度尺度是否同向恶化（排除短期峰谷）

4. **社区外部互动（Attention / Engagement，辅助维度）**  
   目标是刻画外部关注与互动是否衰减，但该维度不作为“衰退”单独判定依据，仅用于解释与分型：  
   - “外部下降、内部稳定”更像成熟期自然减速；  
   - “外部稳定、内部效率恶化”更像维护资源不足；  
   - “外部与内部同步恶化”才显著提升衰退风险等级。

5. **OpenRank（跨维度综合参照信号）**  
   我们显式纳入 OpenDigger 提供的 OpenRank 指标（仓库/开发者的全域与社区维度，以 OpenDigger 给出的 openrank.json / community_openrank.json 等文件为准）作为：  
   - 生态价值流的“稳健参照轴”（不替代治理指标，但用于分型与排序）；  
   - 避免“只看事件量”的观察者效应风险：当事件量下降但 OpenRank 长期稳定时，更倾向判断为成熟稳定而非衰退。
   
### 衍生特征口径：在不改动 OpenDigger 原始指标的前提下，构造可解释的治理特征层

对任一 OpenDigger 月度指标序列 $x_t$（$t$ 为月份），我们在特征工程层构造三类派生特征，用于“排除季节性/生命周期干扰 + 强化持续性判断”：  
- **Change（相对变化）**：  
  - 月环比：与 $t-1$ 月或上一个窗口的对比；  
  - 同比：与 $t-12$ 同月对比（若数据跨度允许），用于识别“假期低谷/周期性峰谷”与“异常持续下滑”的差异；  
- **Trend（趋势一致性）**：季度尺度（`YYYYQX`）与月度尺度是否同向；  
- **Stability（稳健性）**：对缺失或插值月份，标注 raw/插值来源，作为解释时的可信度提示。

这些派生特征不改变 OpenDigger 指标本身，而是作为本项目的“治理特征层”，在后续模块中用于风险评分、证据链与建议生成。

### 衰退信号定义：从“指标”到“信号”的可配置规则（Signal Dictionary）

为了让“衰退”在工程上可复现、可审计、可解释，我们将其拆解为一组基础信号（Signal），每个信号均由三部分组成：  
- **Window（窗口）**：以月度为基本单位，可组合季度对照；  
- **Condition（条件）**：基于同比/环比/趋势一致性等派生特征；  
- **Consistency（一致性）**：要求连续 $k$ 个月满足，且至少 $m$ 个维度共同触发，避免单指标误判。

典型信号（示例，具体阈值与窗口全部配置化）：  
- **活跃度持续下滑信号**：活跃类指标同比为负且连续 \(k\) 个月成立，同时季度尺度同向下行；  
- **协作效率恶化信号**：效率类指标（如 Issue Age 等）持续变差，并与 backlog/关闭相关指标出现同向压力（以 OpenDigger可用指标为准）；  
- **贡献者流失/集中度异常信号**：贡献者规模下降与贡献集中度上升共同出现（提示单点维护风险）；  
- **供需失衡信号**：协作事件“新增”与“处理完成”长期不匹配（表现为积压压力与效率恶化共同出现）；  
- **外部关注衰减信号（辅助）**：仅在与内部治理信号同时出现时提高风险等级，用于分型解释而非单独判定。

### 配置化与可复现承诺：Metric Dictionary / Signal Dictionary 两份配置文件固化口径

为保证“可复现、可审计、可迁移”，我们将数据与信号的口径固化为两份配置：  
- `metrics.yaml`：逐条列出所用 OpenDigger 指标（对应文件路径、对象类型 repo/dev、月/季/年粒度、是否保留 raw、缺失处理策略）；  
- `signals.yaml`：逐条列出信号规则（窗口长度、同比/环比条件、连续性 \(k\)、一致性 \(m\)、信号权重、解释模板）。  

运行时严格执行：  
1) 仅从 OpenDigger 静态数据根链接拉取原始指标 JSON；  
2) 原始指标入库后保持只读；  
3) 所有派生特征与信号判定均可由配置复现，并输出可追溯的“证据摘要”（指标来源文件、触发月份、raw/插值标记）。

---

## 第 6 页｜IoTDB 时序数据建模与存储设计（技术挑战 + 设计方案）

### 为什么一定要用 IoTDB（而不是 MySQL “也能存就行”）

本项目的核心数据形态是“多项目 × 多指标 × 长时间跨度”的多维时间序列：每个开源仓库（repo）对应一组随时间变化的指标（活跃度、贡献者结构、协作效率等），且分析过程高度依赖“按时间窗口的聚合/下采样”“滑动窗口计算”“多指标结果按时间戳对齐输出”“缺失点处理”。MySQL 当然能存，但在工程实现上会遭遇三个典型痛点：  
- **时间粒度不一致导致的对齐成本高**：OpenDigger 的不同指标可能按周/按月或存在缺测。若在通用关系库侧手写对齐逻辑，往往需要大量 ETL、临时表与复杂 JOIN，且难以复用与审计。IoTDB 提供面向时间序列的查询与对齐能力，可把“对齐”从 ETL 负担变成数据服务的一部分。  
- **窗口聚合/下采样是主工作负载**：我们的建模、看板与解释都需要大量按时间窗口的聚合查询（周/月级 downsampling、固定窗口统计、滑动窗口特征）。IoTDB 对时间序列聚合查询更贴合这一负载模式，从而减少重复计算与口径漂移。  
- **缺失值是常态**：生态数据中缺测/空值普遍存在。IoTDB 支持在查询侧进行缺失值填充（FILL 语义），可让下游可视化与特征导出更稳定，避免每个模块重复处理空值。  

### 数据模型：把 repo 当作 device，把指标当作 measurements

我们采用 IoTDB 的“实体（device）—测点（measurement）”建模方式：  
- **device**：用 repo 的唯一标识表示一个实体（如 `org/repo` 或 `repo_id`）。  
- **measurement**：每个 OpenDigger 指标以及我们生成的衍生指标都是一个 measurement。  
- **timestamp**：以周（`week_start`）或月（`month_start`）作为时间戳基准，必要时保留数据源的原始时间戳用于追溯。  

写入侧，我们将同一 repo 的多指标尽量按同一时间点批量写入；在合适场景使用 **Aligned Timeseries**（同一实体下的一组测点共享时间列），减少时间列重复存储，并优化“同一周/月写入多指标”的典型模式。  

### 两层序列：原始指标层 + 衍生特征层（可复现、可回放）

IoTDB 中的时间序列分两类，分别服务“可追溯”与“可计算”：  
- **`raw.*`（原始指标序列）**：从 OpenDigger 直接采集的指标（如 `issue_opened`、`pr_merged`、`active_contributors` 等，字段以实际可用为准），并记录来源版本/采集时间，便于追溯。  
- **`feat.*`（衍生特征序列）**：由原始指标生成、直接供建模与解释使用的特征序列，包括：  
  - **平滑序列**：滚动均值/滚动中位数（抑制噪声与节假日短期波动）。  
  - **趋势序列**：滚动斜率、变化率（WoW/MoM/YoY 的相对变化）。  
  - **波动/异常序列**：滚动方差、异常分数（识别“超出历史正常范围”的偏离）。  
  - **复合信号序列**：把“活跃度下降 + 贡献者减少 + 积压上升”等组合成可解释的 `signal_score`。  

工程收益是：特征“落库为可查询序列”，看板、模型与解释模块共享同一口径；评委可通过同一数据快照复现任意一次风险评分，并对历史版本做回放对比。  

### 对齐与下采样：用 IoTDB 的时间对齐与聚合语义解决“指标粒度不一致”

OpenDigger 指标的时间粒度不一致与缺测，使得“对齐”成为工程痛点。我们将对齐与聚合下推到 IoTDB 层，统一输出建模口径：  
- **对齐输出（Time Alignment）**：查询结果按时间戳对齐输出，同一行对应同一 `timestamp`，减少多指标拼表成本与口径漂移。  
- **按设备批量对齐（ALIGN BY DEVICE）**：当需要批量导出多 repo 的特征（训练/回测/对比分析）时，用 `ALIGN BY DEVICE` 将 repo（device）纳入结果维度，显著降低多 repo 拼表与 JOIN 的复杂度。  
- **下采样与滑窗聚合（GROUP BY 时间窗口）**：对看板与训练数据构造，广泛使用基于时间窗口的聚合语义生成周/月级序列，并支持设置窗口大小与步长以实现滑动窗口统计（例如“8 周窗口、每 1 周滑动一次”），从而把 rolling_mean/rolling_slope 等特征计算下推到查询层。  
- **缺失值处理（FILL）**：对齐后出现的 NULL/缺测会影响可视化与模型特征，我们在特征导出查询中使用 `FILL` 进行查询侧填充（如 `previous`、`linear` 等按指标类型选择），保证下游管线稳定。  

### 工程实现：写入策略、元数据与可运维性（可复现、可运行）

为保证系统可落地与评审可复现，我们采用“全量初始化 + 增量刷新 + 版本化口径”的工程策略：  
- **全量入库 + 增量更新**：首次对目标项目集做全量回灌；随后以周为单位增量写入最新窗口，并对衍生特征做“近窗重算”（例如只重算最近 12 周相关窗口，避免全量重算）。  
- **命名规范与元数据标签**：统一 device 命名（`repo_id/org_repo`），并记录项目属性（语言、领域、创建时间、组织等），用于 DataEase 分组对比与 SQLBot 的自然语言筛选。  
- **数据版本与回溯**：每次特征生成与风险评分记录数据版本号（数据截至时间、窗口参数、阈值配置版本），确保“同一输入必得同一输出”，支持回放与对比回测。  
- **对下游友好接口**：为 DataEase/SQLBot 提供固定的导出视图（按 `repo + time` 的宽表/长表），IoTDB 负责“对齐、聚合、填充”，应用层专注“展示与交互”，避免前端工具重复做复杂计算。  

---

## 第 7 页｜风险预测模块：任务定义、弱监督标签与模型方案（技术挑战 + 创新性）

在缺少“衰退/不衰退”人工标注的前提下，本模块将风险预测定义为一个**弱监督 + 多任务时序学习**的工程问题：一方面，用可复现的规则在历史数据上自动构造训练信号，保证系统可持续迭代；另一方面，用**可部署的轻量深度时序模型**在多指标序列中捕捉非线性、滞后效应与跨指标耦合关系，形成明显技术亮点，并为后续解释与治理建议提供更可靠的证据链。

为避免与数据源口径冲突，本方案默认使用 **OpenDigger 官方静态指标的月度（`YYYY-MM`）序列**作为主时间粒度；季度（`YYYYQX`）与年度（`YYYY`）用于稳健参照与生命周期校验。若需要更细粒度视角，则由 IoTDB 侧以窗口统计形成“近似周级信号”，并明确标注为派生结果（非 OpenDigger 原生粒度），避免口径混乱。

### 任务定义：从“硬分类”升级为“概率化风险 + 多步趋势预测（多任务）”

对每个项目在时间 $t$ 的状态，构造输入窗口 $X_{t-L:t}$，其中包含过去 $L$ 个时间步的多维指标序列与衍生特征：
- 时间粒度：月度（YYYY-MM）
- 典型窗口：$L = 12\sim18$ 个月（覆盖一个完整年度周期，便于处理季节性）
- 输入内容：OpenDigger 指标（活跃度、贡献者结构、协作效率、外部互动等）及其派生特征（滚动均值/中位数、趋势斜率、同比/环比、稳健异常度等），派生特征在 IoTDB 侧统一计算并落库。

模型输出包含两条互补产物：
1. **多步趋势预测** $\hat{Y}_{t+1:t+H}$：对若干关键治理指标（或其“变化率/标准化后序列”）进行未来 $H$ 步预测（例如 $H = 2\sim3$ 个月），用于刻画“未来是否会持续恶化”的趋势证据；同时输出不确定性区间（例如分位数区间）以衡量预测可信度。
2. **衰退风险概率** $p_t\in[0,1]$ 与风险等级：直接输出“未来窗口内出现持续性、多维一致性恶化”的概率，用于告警与资源分配。

工程意义：风险不再是单次硬判断，而是**可阈值调优的概率输出**；多步预测提供“趋势证据”，可显著增强解释与建议模块的可信度。

### 弱监督标签构造：定义“未来窗口衰退事件”，并用软标签/PU 思路降低噪声

我们为每个时间点 $t$ 自动构造“未来窗口衰退事件”标签。设未来观察窗口为 $t+1\sim t+H$（例如未来 2–3 个月），衰退事件由若干基础信号组合触发（信号来自第 5 页的 Signal Dictionary，且在 IoTDB 侧可复现计算）：

- （a）活跃度类信号恶化：复合活跃度的滚动均值下降，且同比（YoY）同步变差（用于排除节假日/周期性低谷）。
- （b）贡献者结构信号恶化：活跃贡献者规模下降，或贡献集中度显著上升（提示单点维护风险）。
- （c）协作效率信号恶化：效率类指标持续变差（例如 Issue Age 等 OpenDigger 口径指标），并伴随积压压力上升/处理能力下降的组合模式。
- （d）供需失衡信号：新增与关闭的差值持续扩大（体现“处理不过来”）。

**持续性与一致性约束（降低误标）**  
- 持续性：要求信号在连续 $k$ 个月成立（例如 $k\in\{2,3\}$）。  
- 一致性：要求至少 $m$ 个不同维度共同触发（例如 $m\in\{2,3\}$），避免单指标下滑误判。

**从硬标签升级为软标签（更贴合弱监督）**  
相比直接给出 $z_t\in\{0,1\}$ 的硬标签，我们更倾向构造**风险强度软标签** $\tilde{z}_t\in[0,1]$：  
- $\tilde{z}_t$ 由“触发信号数量 + 信号严重度（标准化强度）+ 持续月数”综合得到；  
- 软标签更能表达弱监督的不确定性，也更利于后续概率校准。

**PU/负例降权策略（工程稳健性）**  
在弱监督场景下，$\tilde{z}_t$ 低并不等价于“确定安全”，更像“未观测到明显衰退”。训练时我们将高置信样本当作正例，其余样本视为未标注或低风险样本，并通过**负例降权/PU 思路**降低误把潜在衰退当负例的风险（工程上可配置实现，不依赖人工标注）。

所有标签构造参数（窗口 $L,H$、阈值、$k,m$、信号权重、软标签映射方式）均配置化固化在仓库中，保证可复现、可审计、可做敏感性分析。

---

### 模型方案：可部署的轻量时序 Transformer（MVP）+ 可选自监督预训练

本项目定位偏工程应用，模型设计强调“能跑通、可部署、可解释、可迭代”。因此我们采用**一条清晰主线（MVP）+ 一条明确升级项**，避免堆砌模型导致实现不可控。

**MVP 主模型：轻量 Temporal Transformer Encoder + 双头输出（预测头 + 风险头）**
- **输入表示**：以“时间步为 token”，指标维度作为特征向量；叠加时间位置编码（月序号）与可选静态条件（语言/领域/组织等元数据，用于项目分层对比与泛化）。  
- **主干网络**：轻量 Transformer Encoder（层数与隐藏维度可控），重点学习跨指标耦合与长程依赖（例如“贡献者减少”对后续“效率恶化”的滞后影响）。  
- **输出双头**：  
  1) **趋势预测头**：对关键指标的未来 $H$ 步输出分位数区间（如 $q_{0.1}, q_{0.5}, q_{0.9}$），用于不确定性表达；  
  2) **风险分类头**：输出 $p_t$（衰退风险概率），训练时对弱监督软标签/PU 权重适配。

**训练目标：多任务联合，弱标签更稳**
整体损失函数：
$$
\mathcal{L}=\lambda_1 \mathcal{L}_{forecast}+\lambda_2 \mathcal{L}_{risk}
$$
- $\mathcal{L}_{forecast}$：使用分位数损失（pinball loss）或稳健回归损失；对计数型指标先做 $\log(1+x)$ 等变换，或预测“变化率/标准化序列”再反变换，以适应长尾与尺度差异。  
- $\mathcal{L}_{risk}$：使用二元交叉熵并引入样本权重（高置信正例更高权重、其余样本负例降权/PU），以缓解弱标签噪声与类别不平衡。

多任务的工程价值：即使风险标签存在噪声，趋势预测仍提供稳定学习信号，使训练更稳、泛化更好。

**升级项：自监督预训练（仅保留一种，确保可交付）**
在大量无标签项目序列上进行**Masked Time-Series Modeling**：随机遮蔽部分时间步/部分指标，让模型重建被遮蔽片段，获得通用时序表示；随后用弱监督标签微调双头任务。  
该升级项的价值在于：在标注稀缺条件下显著提升表示质量，且“预训练一次，多处复用”，工程上可落地、可解释、可复现。

---

### 风险输出与运营分级：概率校准 + 阈值策略配置化

模型输出 $p_t$ 需经**概率校准**提升可用性（避免过度自信）：在滚动回测集上使用 Platt scaling 或 isotonic regression 拟合校准器，得到校准后的 $\tilde{p}_t$。  
随后映射为风险等级（低/中/高）：
- 低风险：$\tilde{p}_t < \tau_1$
- 中风险：$\tau_1 \le \tilde{p}_t < \tau_2$
- 高风险：$\tilde{p}_t \ge \tau_2$

阈值 $\tau_1,\tau_2$ 不硬编码，而是通过历史滚动回测在“误报成本 vs 误报成本”的治理偏好下选择，并支持不同角色策略（维护者/OSPO/基金会）配置化。

同时利用分位数预测区间宽度作为不确定性指标：当区间过宽或数据缺测比例过高时，输出“需要人工复核”状态，避免给出不可靠的强结论。

---

### 可解释输出：在线轻量解释 + 离线审计解释（工程可行）

为后续 LLM 建议提供“有据可依”的证据结构，本模块输出统一的 RiskReport：
- 连续风险分数 $\tilde{p}_t$
- 离散风险等级（低/中/高/需复核）
- 主导触发信号列表（来自 Signal Dictionary 的可解释规则信号）
- 趋势证据摘要（过去窗口统计 vs 未来预测中位数/分位数区间）

解释策略分两层，确保工程可用：
- **在线解释（默认）**：规则信号触发 + 模型注意力/梯度×输入等轻量重要性（仅用于排序与提示）；  
- **离线解释（审计/样例报告）**：对少量关键样本使用 Integrated Gradients / SHAP 做深入归因，用于模型可信度审计与案例展示，不作为实时链路的硬依赖。

通过以上设计，本模块在工程交付上保证“弱监督标签可复现、训练可迭代、推理可部署”；在技术亮点上体现“轻量时序 Transformer + 多任务学习 + 概率校准 + 证据化解释”，并与前述 OpenDigger（官方口径）与 IoTDB（窗口化与对齐能力）实现严格对齐。。

---

## 第 8 页｜风险解释与归因：从“分数”到“证据链”（创新性 + 应用场景）

为了避免系统沦为“黑盒打分器”，我们将**解释模块**设计为一等公民，并明确其工程目标：解释不是为了给出学术性的可解释性指标，而是为维护者与 OSPO 提供**可验证、可复现、可行动的证据链（Evidence Chain）**。该证据链回答三个核心问题：  
1）**何时开始变差**：关键治理信号从哪个时间点起出现持续性恶化（不是单点波动）；  
2）**变差有多严重**：恶化幅度是否显著、是否超出历史正常波动范围（排除季节性/周期性）；  
3）**意味着什么、该做什么**：该恶化通常对应哪些治理含义与可执行干预手段（例如效率下降往往意味着 triage 压力上升或维护资源不足）。

### 解释主线：结构化“信号解释”优先，深度模型解释作为补充

解释模块以“**信号检测器（Signal Detector）** + **证据生成器（Evidence Builder）**”为主线运行。我们优先输出**规则信号的证据链**，保证可审计与可复现；深度学习模型的解释（注意力/梯度类重要性）只作为“辅助排序与补充线索”，不作为唯一依据，从而确保工程可信度与可落地性。

信号基于 OpenDigger 指标（月度为主）及其在 IoTDB 侧可复现计算的衍生统计（滚动均值/中位数、同比/环比、趋势斜率、稳健异常度等）。

### 工程实现：Signal Detector（检测）→ Evidence Builder（证据）→ RiskReport（统一输出）

**1. Signal Detector：标准化信号、强度与置信度**
对每个项目在评估时刻 \(t\)，解释模块计算一组标准化治理信号（示例）：
- **活跃度持续下滑信号**：滚动均值下降 + 趋势斜率为负 + 同比同步恶化（用于排除季节性低谷）。
- **贡献者流失/单点风险信号**：活跃贡献者下降，或贡献集中度异常升高（提示关键人依赖）。
- **协作效率恶化信号**：效率类指标（如 Issue Age 等 OpenDigger 口径）持续变差，且异常度升高。
- **供需失衡/积压压力信号**：新增与关闭差值持续扩大，或“处理能力”无法覆盖“需求进入”。

每条信号输出两类数值：
- **signal_strength（强度）**：基于标准化后强度（例如同比/环比幅度、斜率大小、异常度偏离程度）计算，统一映射到可比较的标度。
- **signal_confidence（置信度）**：用于表达“证据是否可靠”，由数据完整性、窗口覆盖度、季节性一致性检验结果与多维一致性情况共同决定（例如：缺失率高或预测不确定性高则置信度降低）。

**2. Evidence Builder：把信号变成“可验证证据”**
对强度最高的 Top-N 信号（例如 N=3~5），证据生成器为每个信号构建**可直接验证的证据包**，确保评委与用户可以“看见并复核”：
- **when（起始点）**：恶化开始的最早时间点 \(t_0\)，以及持续月数 \(k\)（强调持续性，而非单点下降）。
- **how_much（幅度）**：过去窗口 vs 当前窗口的对比统计（滚动均值/中位数差异、同比/环比变化率），并给出阈值对照。
- **is_abnormal（是否异常）**：相对历史分布的异常度（如分位数偏离或稳健 z-score），用于区分“正常周期波动”与“异常持续下滑”。
- **visual_evidence（可视化证据描述）**：明确将展示哪些曲线与参考线（例如：原序列 + 滚动均值 + 阈值线 + 同比对比曲线），并标注触发窗口区间，保证解释可复核。
- **governance_meaning（治理含义）**：将信号映射到治理语境下的可解释含义（例如效率变差常见于 triage 资源不足、流程阻塞、维护负担增加等）。

### 与深度学习模块的衔接：从“模型输出”到“证据优先”的一致解释

第 7 页模型输出风险概率 $\tilde{p}_t$ 与趋势预测区间后，解释模块遵循**证据优先**原则：
1）先用 Signal Detector 给出可复现的规则证据链（主解释）；  
2）再用模型的轻量重要性线索（例如注意力/梯度×输入）辅助说明“哪些时间段/哪些特征对风险判断贡献更大”；  
3）当模型预测不确定性过高或数据缺失严重时，解释模块会降低置信度并输出“需复核”标记，避免强行给出确定性结论。

这样可以保证：即便深度模型升级或替换，解释模块仍保持稳定接口与可审计证据，符合“分阶段可升级”的工程策略。

### 输出形态：结构化 JSON 作为下游 LLM 建议的唯一入口（关键创新点）

解释模块最终输出统一的结构化对象（可直接落库/前端渲染/喂给 LLM），核心字段包括：
- `risk_score`：校准后的风险概率 $\tilde{p}_t$
- `risk_level`：低/中/高/需复核
- `main_signals[]`：主导信号列表（按强度排序）
- `main_signals[].signal_name / signal_strength / signal_confidence`
- `main_signals[].time_window`：触发窗口与起始点
- `main_signals[].supporting_metrics`：支撑指标摘要（过去窗口 vs 当前窗口 vs 同比参照）
- `main_signals[].evidence_refs`：可视化证据所需的序列与参考线说明（用于 DataEase 看板呈现）
- `data_quality`：缺失率、覆盖度、窗口有效性等
- `model_uncertainty`：预测区间宽度等不确定性提示（用于告警策略）

我们坚持“**先结构化、再生成**”：LLM 建议模块只接收该 JSON 与知识库检索结果，不直接阅读原始指标表，从而将大模型的输出约束为“基于证据的治理建议”，显著提升可信度、可控性与可复现性。这一流程是本作品在工程可信度与评审答辩中的关键创新点之一。

---
## 第 9 页｜LLM 治理建议模块：定位、输入约束与知识增强（创新性 + 技术挑战）

我们将大模型模块严格定位为 **“治理建议生成器（Action Generator）”** ，而不是“风险判别器”。本系统的风险判别必须由第 7 页的可复现风险模型（第一阶段可部署的 MVP 深度模型，第二阶段可选自监督增强）以及第 8 页的证据链解释机制共同完成；LLM 的价值在于：**把结构化证据翻译成维护者能执行的行动方案**，并在治理最佳实践的约束下输出具体可落地的步骤清单。换言之，LLM 不负责“发现风险”，只负责“基于已确认的风险证据提出治理动作”，这是控制幻觉与保证工程可信度的关键设计。

### 输入约束：只喂“RiskReport 证据对象”，不喂原始时序数据

为显著降低幻觉风险，LLM **不直接读取 OpenDigger 原始指标表或任何未结构化的时序数据**，而是只接收第 8 页输出的 **RiskReport JSON** 作为唯一事实来源。RiskReport 至少包含：
- `risk_level / risk_score / model_uncertainty`
- `main_signals[]`（信号名、强度、置信度、触发窗口）
- `supporting_metrics`（过去窗口 vs 当前窗口 vs 同比参照的摘要统计）
- `data_quality`（缺失率、覆盖度、是否需复核）
- `evidence_refs`（前端可视化所需的曲线与阈值线描述）

这种输入约束把 LLM 的职责从“推断事实”降维为“基于已给事实进行解释与行动建议”，使其输出天然可控、可审计，并能与第 8 页证据链一一对应。对于 `risk_level=需复核` 或 `model_uncertainty` 过高的样本，LLM 必须先输出“需要人工复核/补充信息”的提示，并给出最小化的核查步骤，避免过度自信。

### 输出约束：模板化行动计划，确保“可执行、可检查、可复盘”

LLM 生成内容采用**模板约束 + 结构化输出**，避免泛泛而谈。每次输出固定包含三段：
1. **风险摘要**：一句话概括当前风险等级、主要驱动信号与不确定性（若有）。
2. **逐信号治理建议（逐条对齐 main_signals）**：每个主导信号必须输出“原因解释 + 动作清单”，并包含：
   - `目标（Goal）`：要解决什么问题（例如降低 triage 压力、缩短反馈时延、扩大贡献者池）。
   - `步骤（Steps）`：3～6 个可操作步骤（尽量具体到维护流程、仓库配置、社区动作）。
   - `预期效果（Expected Impact）`：能改变哪些指标/信号（与 supporting_metrics 对齐）。
   - `注意事项（Risks/Trade-offs）`：副作用与约束条件（例如需要维护者投入、可能影响发布节奏）。
3. **优先级与 30/60/90 天计划**：给出短中期可落地节奏，便于 OSPO/维护者执行与复盘。

同时强制约束：建议中**不得出现 RiskReport 未提供的“新事实”**（例如“项目已经流失 30% 贡献者”这类未经 supporting_metrics 支撑的断言）。若需要补充事实，必须通过 SQLBot/看板查询或标记“需人工确认”。

### 知识增强：MaxKB 治理知识库 + 信号到知识条目的可追溯映射

为了让建议“具体而不编造”，我们采用 **RAG（检索增强生成）**：MaxKB 用于沉淀可复用的开源治理知识库与最佳实践条目，例如：
- Issue/PR triage 与标签体系（分流、SLA、模板、自动化分派）
- Release/roadmap 管理与版本节奏
- 贡献者引入与激励（good first issue、mentor 机制、贡献指南）
- 文档与沟通治理（FAQ、公告、社区渠道维护）
- 核心维护者扩容与 bus factor 风险缓解

工程上我们建立**“信号 → 知识主题”映射表**：例如“协作效率恶化信号”优先检索 triage/SLA/自动化分派相关条目，“贡献者流失/集中度异常”优先检索贡献者培养与维护者引入流程相关条目。LLM 生成建议时必须引用检索到的条目摘要作为依据，并在输出中保留 `knowledge_refs`（条目 ID/标题/片段来源），便于追溯与复用。

### 交互增强：SQLBot 面向运营/治理人员的自然语言查询入口

对于“我要查哪些项目最危险/哪些指标变化最大”这类运营问题，我们引入 SQLBot 作为自然语言到查询语句的接口，用于调用 IoTDB 中的原始/衍生指标与 RiskReport 表。典型查询包括：
- “过去 6 个月协作效率恶化最快的 Top20 项目”
- “近 3 个月贡献者下降且集中度上升的项目有哪些”
- “本周高风险项目中，哪些信号最常见（用于治理策略复用）”

SQLBot 的作用不是替代看板，而是**降低检索门槛**并增强“证据可查”的闭环能力：用户可以对 LLM 给出的每条建议进行快速验证与复盘。

### 可控性承诺：证据链驱动、可追溯、可复盘

本模块的成熟度体现在三点可控承诺：
- **证据链驱动**：输入只来自 RiskReport，输出必须逐信号对齐；
- **知识可追溯**：建议来自 MaxKB 检索条目，保留 `knowledge_refs`；
- **可复盘可迭代**：建议执行后可通过 IoTDB 指标变化与 RiskReport 回测验证效果，形成治理闭环。

这种“结构化证据 → 检索增强 → 模板化建议”的链路，使大模型在开源治理场景下既能体现创新性，又能满足评委最关注的工程可信度与可落地性。

---

## 第 10 页｜可视化与交互：DataEase 看板与查询体验（实现效果导向的设计方案）

**为何选择 DataEase（面向“实现效果/可访问性”的取舍）**
- **快速出效果**：面向运营/治理人员，DataEase 支持通过**鼠标点击与拖拽**快速制作图表与仪表板/数据大屏，降低前端开发成本，把精力集中在指标体系与风险逻辑上。
- **多终端交付**：看板同时面向维护者与 OSPO/运营人员，展示端支持 **PC / 移动端 / 大屏**，便于路演与日常使用。
- **易集成与可扩展**：支持连接多类数据源（关系型数据库、数据文件、数据仓库、API 等），并支持**跨源查询**能力；便于将 IoTDB 的结果表/视图与其他辅助数据（如项目元信息）在展示层汇合。
- **可分享、可嵌入、可控**：支持多样化分享方式与安全控制；在复赛阶段可进一步将关键看板以嵌入方式集成到统一门户，形成“可访问的演示环境”。

**看板信息架构（3 层设计：发现 → 诊断 → 行动）**
1. **项目集群总览层（1 分钟定位问题）**
   - 风险等级分布（低/中/高）
   - 风险 Top 列表与“近期上升最快”列表（支持按组织/领域/语言过滤）
   - 关键维度对比：活跃度、贡献者、协作效率三类维度的“异常项目占比/趋势”
   - 目标：让用户快速回答“**哪个项目最需要看**、为什么是它”

2. **单项目诊断层（验证与定位原因）**
   - 关键指标时序曲线（原始 + 平滑/滚动统计）
   - “信号触发时间段”标注（例如持续下滑区间、积压上升区间）
   - 历史窗口对比（过去窗口 vs 当前窗口；同比/环比对照）
   - 解释模块输出：主导信号列表 + 强度/置信度 + 支撑指标摘要
   - 目标：让维护者能回答“**哪里开始变差、变差到什么程度、是否超出正常波动**”

3. **行动建议层（把证据变成可执行动作）**
   - 展示 LLM 生成的治理建议，并与主导信号逐条对齐（“信号 → 原因 → 建议动作”）
   - 建议反馈入口（采纳/不采纳/备注/复盘结论）
   - 若初赛时间不足：先实现“建议展示 + 证据对齐”，复赛补齐“采纳记录/闭环复盘”

**交互闭环设计（看板为主，查询为辅）**
- **看板交互（DataEase 原生能力）**：过滤（组织/领域/语言/时间窗）→ 钻取到单项目 → 查看信号与证据。
- **自然语言查询（SQLBot）**：用于运营人员的临时探索与验证，例如：
  - “最近 3 个月贡献者下降但提交量未下降的项目有哪些？”
  - “哪些项目积压增长但关闭率稳定？”
- 定位：自然语言查询不替代看板，而是补足“临时问题快速验证”，形成  
  **看板发现 → 语言查询验证 → 回到看板决策/记录** 的闭环。

**复赛交付承诺**
- 提供可访问的演示环境（公开样例数据 + 脱敏配置），看板可直接体验。
- 在仓库给出：看板结构说明（IA）、数据字段映射表、典型截图与复现步骤，确保评委可快速验证“看板—解释—建议”的端到端闭环。

---

## 第 11 页｜工程实现计划：模块划分、接口契约与里程碑（设计方案）

为保证方案“可实现、可落地、可指导开发”，我们采用面向服务的工程拆分：**四个后端模块 + 一个展示层**，以“数据—风险—证据—建议—看板”的闭环为主线推进。整体原则是：先把链路跑通并可复现，再逐步提高预测质量与交互体验，避免复赛阶段在模型炫技上投入过多导致工程翻车。

### 模块划分：四个服务模块 + 展示层（职责清晰、可并行开发）

**（1）数据采集与标准化服务（Ingestion Service）**  
负责对接 OpenDigger 数据获取与更新，输出统一的标准化指标表（按 repo、时间粒度对齐）。工程职责包括：项目清单管理、增量同步调度、数据校验（缺失/异常/重复）、以及将“原始指标 + 元数据（repo 信息）”落地为可入库格式。该模块不做复杂建模，只保证数据链路稳定、可追溯。

**（2）时序存储与特征计算服务（TSDB Service / Feature Service）**  
负责将原始指标与衍生特征写入 IoTDB，并提供统一查询接口。衍生特征的计算遵循配置化（窗口长度、平滑方式、同比/环比计算等），并尽量在 IoTDB 侧完成窗口聚合与对齐计算，减少离线清洗成本。该模块对外提供：按 repo/时间范围的指标查询、按窗口的聚合查询、以及 RiskReport 生成所需的特征取数接口。

**（3）风险评估与证据生成服务（Risk & Evidence Service）**  
负责定期执行风险推理与解释对象生成：从 IoTDB 拉取特征序列，运行风险模型/规则输出 `risk_score/risk_level`，同时计算并产出“证据链”——主导信号列表、信号强度、触发窗口、支撑指标摘要与数据质量标记（是否需复核）。产出结果以结构化形式写回数据库（或缓存），供看板与建议服务消费。该模块强调：可复现（参数可追溯）、可回测（按时间滚动验证）、可审计（证据可对齐）。

**（4）建议生成与知识增强服务（Advisory Service）**  
负责接收 RiskReport（证据对象），调用 MaxKB 进行治理知识检索（RAG），再调用 LLM 生成**模板化、可执行**的治理建议，并将建议与引用来源（knowledge refs）持久化。该模块明确边界：不进行风险判别，只基于证据做“解释与行动方案生成”，并对输出做格式校验与安全约束（不得引入 RiskReport 未提供的新事实）。

**（5）展示层（DataEase + API/查询入口）**  
DataEase 用于搭建运营视角看板（排行榜/项目详情/证据链曲线/复盘对比）。展示层通过 API 获取 RiskReport 与建议结果；对探索性问题，提供 SQLBot 作为自然语言查询入口（面向运营人员降低取数门槛），并将查询结果可视化或用于验证建议依据。

### 接口契约：以 RiskReport 为“系统事实对象”，保证可维护与可扩展

模块之间采用清晰的接口契约，核心契约对象为 **RiskReport**，它是系统对外输出的“事实与证据载体”，任何模块升级不应破坏该契约（允许加字段，不允许改语义/删字段）。RiskReport 建议包含以下字段组：

- **身份与版本**
  - `repo_id / repo_full_name / platform`
  - `as_of_time`（评估时刻）
  - `granularity`（week/month）
  - `pipeline_version / model_version / config_hash`（复现关键）
- **风险结论**
  - `risk_score`（0~1）
  - `risk_level`（low/medium/high/review）
  - `model_uncertainty`（可选：区间宽度/置信度）
- **证据链（解释对象）**
  - `main_signals[]`：`name / strength / confidence / trigger_window`
  - `supporting_metrics`：过去窗口 vs 当前窗口 vs 同比参照的摘要统计
  - `evidence_refs`：可视化所需曲线描述/阈值线/对比窗口
  - `data_quality`：缺失率、覆盖度、异常标记（是否需复核）
- **建议输出（可选）**
  - `advice_text`（模板化行动计划）
  - `knowledge_refs[]`（MaxKB 条目引用，用于追溯）

我们将在仓库提供：RiskReport JSON 示例、字段定义（Schema）、指标字典（Data Dictionary）与端到端样例请求/响应，确保能快速理解并复现链路。

### 开发计划：先闭环可跑通，再提升效果

以复赛交付为目标，采用“可跑通闭环优先”的里程碑策略：

**M1｜数据链路与入库（可运行）**  
- 完成 OpenDigger 数据采集与增量同步脚本  
- IoTDB 写入原始指标 + 基础衍生特征（窗口聚合、同比/环比）  
- DataEase 初版看板：项目趋势曲线 + 基础指标对比  
- 交付：一键启动/数据初始化脚本、基础数据字典

**M2｜风险评分与证据链（可解释）**  
- 完成 Risk & Evidence Service：规则/基线模型 + 信号检测器  
- 输出 RiskReport（含主导信号、支撑统计、数据质量）并可回测  
- 看板升级：风险排行榜 + 项目详情（信号与阈值线可视化）  
- 交付：RiskReport Schema、回测报告（误报/漏报示例解释）

**M3｜建议生成（可控）**  
- 建立 MaxKB 治理知识库（条目化：triage、贡献者引入、release 管理等）  
- Advisory Service：RiskReport → 检索 → 模板化建议生成，保留引用来源  
- SQLBot 接入：自然语言查询验证证据/辅助运营分析  
- 交付：建议模板、RAG 引用示例、可追溯输出样例

**M4｜工程完善与作品材料（可复现、可展示）**  
- 完善部署（Docker Compose/脚本）、配置管理、日志与监控  
- 完整 README、架构图、接口文档、复现指南  
- 演示视频与答辩脚本：展示“风险—证据—建议—复盘”的闭环  
- 交付：可复现仓库、演示数据/脚本、完整 PPT

### 分工与并行开发建议

- **数据采集/IoTDB 入库** 与 **看板搭建** 可并行推进（先用样例数据跑通看板）。
- **风险评估与证据链** 在 M1 完成后即可迭代（先规则/基线，后续再升级模型不破坏接口）。
- **建议服务与 MaxKB** 可在 M2 输出稳定 RiskReport 后接入，避免建议系统在证据不稳定时反复返工。

通过上述拆分与里程碑倒排，我们确保：即使模型部分后续升级，系统仍能稳定交付“可跑通、可解释、可复现”的工程闭环。

---

## 第 12 页｜创新点与差异化说明（创新性）

本作品的创新性不依赖“提出全新算法”，而体现在面向开源治理场景的**端到端闭环**与**工程可控性**：我们把生态数据从“静态展示”推进到“可运营的预警与处置”，并让每一步都可审计、可复现、可解释。

1) **从描述到预警：把“生态分析”升级为“风险预警服务”**  
不仅展示历史趋势，还提供面向未来窗口的风险概率/等级输出，使系统能够直接服务维护者与 OSPO 的治理决策，而不是停留在“看热闹的指标面板”。

2) **“信号—证据链—建议”结构化闭环：把大模型从生成器变成执行助手**  
风险分数必须落到可验证的信号；信号必须有可视化证据（时间段标注、窗口对比、阈值触发）；建议必须逐条对齐信号并给出可执行动作，从流程上约束大模型，避免“空话式建议”。

3) **赛项工具集协同：形成可复用的治理平台雏形**  
OpenDigger 负责指标数据供给；IoTDB 承载多指标时序与对齐/聚合；DataEase 提供快速成型的多层级看板；SQLBot 提供自然语言到查询的探索入口；MaxKB 负责沉淀治理知识并为建议提供检索增强，组合形成一个可迁移、可扩展的工程化方案。

与去年常见作品相比，本作品的差异化在于**预测与行动导向**：不仅回答“发生了什么”，更回答“是否会继续变差、该怎么介入”，并用工程约束确保建议质量可控，从而在创新性维度达到“有效组合优化且亮点明显”的高分档位。


## 第 13 页｜应用价值、推广路径与落地方式（应用场景）

**维护者侧（单项目治理）**  
系统作为日常运营助手：按周/按月生成风险报告，指出哪些维度出现持续恶化、恶化从何时开始，并给出可执行的介入建议与优先级排序，帮助维护者把精力集中在最关键的治理动作上。

**OSPO/企业侧（依赖治理）**  
对企业依赖的开源组件池进行风险扫描与分层：识别高风险依赖并提前制定替代或共建计划，降低供应链与技术路线风险；同时可追踪治理动作前后的指标变化，用于评估投入产出。

**基金会/社区运营侧（资源配置与效果评估）**  
识别“值得扶持但出现衰退信号”的项目，辅助制定扶持策略；并用统一指标体系评估活动/资助/共建策略在前后窗口的效果变化，形成可复盘的运营闭环。

**推广路径（从试点到规模化）**  
作品以开源项目交付，提供开箱即用部署与演示数据：先从少量项目试点看板与预警闭环，再扩展到批量项目监控；先周/月粒度稳定跑通，再按数据供给条件扩展更细粒度。底座采用 IoTDB + 指标字典/配置化信号，可迁移到相近时序治理任务（如安全漏洞管理、版本节奏风险、关键贡献者风险等）。


## 第 14 页｜风险与应对、开源规范与交付清单（设计方案 + 技术挑战）

**主要风险**
- 数据缺失/口径不一致导致评分不稳定、跨项目对比困难  
- 弱监督标签存在噪声，可能造成误报/漏报  
- LLM 输出存在泛化或幻觉风险  
- 部署链路复杂，影响“可运行可复现”的评审体验

**应对策略（工程化承诺）**
- 数据侧：统一缺失处理与质量标注（缺失率阈值、过滤规则、口径对齐），并将指标/窗口/阈值配置化固化，保证可审计  
- 评分侧：多信号一致性约束 + 平滑/稳健统计，避免短期波动触发；关键阈值通过历史回测做敏感性分析，选择保守策略降低误报  
- 大模型侧：仅接受结构化证据输入，结合 MaxKB 检索增强与输出模板约束；界面中明确标注“建议对应的触发信号与证据摘要”，提升可控性与可信度  
- 交付侧：提供一键启动脚本与固定版本依赖，确保评委可快速复现；演示环境优先保证“可访问、可体验、闭环可跑通”

**开源规范与交付清单**
- 仓库提供：许可证声明、架构图、模块说明、数据字典、配置说明、运行/复现步骤、截图与演示视频、规范的 Git 记录与分工说明  
- 最终交付：初赛设计方案 PPT；复赛完整 PPT + 可运行代码 + 部署文档 + 演示环境（或本地一键运行方式）  

